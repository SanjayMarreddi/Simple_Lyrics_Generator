{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lyrics_Generation_CB_Workshop.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "44MFYgaWU9N-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#First Let us import the required Libraries\n",
        "import requests \n",
        "import numpy as np"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REhUOdYOezfN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now Let us get the data required from URL\n",
        "response=requests.get(\"https://raw.githubusercontent.com/coding-blocks-archives/ML-Noida-2019-June-Two/master/datasets/speeches/speech.txt\")"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "se_IDlZGe_oq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=response.text"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woIa6deHfM1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checking how our Data Looks\n",
        "print(data[:1500])"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaLNLm4TfBbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I used the algorithm \"Markov Chains\" which is mostly based on Probabilities.\n",
        "\n",
        "# Example:-\n",
        "\n",
        "# Suppose Data availabe with us is:- text=\" the man was .... they then.... the ... the ...\"\n",
        "\n",
        "# Let us denote X=input, y =output (Output length is 1 always as WE ARE USING CHARACTER BASED MODEL)\n",
        "\n",
        "# Current Input window state size be k=3 (We can chose any size randomly) Here it is \"the\"\n",
        "\n",
        "# We will try to generate a Table (with dictionaries while coding) as shown below:-\n",
        "# As We supposed k=3 , We will try to take all possible strings of length 3 and store it under X , character after X will be stored under y(Value we will guess later)\n",
        "\n",
        "# Freq denotes number of times the particular string is followed by a particular Character and we use this to calculate the Probability of having a character after a particular string arrived.\n",
        "\n",
        "#Roughly TABLE looks like this.\n",
        "\n",
        "# X.        y.         freq\n",
        "\n",
        "# the       _           3\n",
        "# he_       m           1\n",
        "# e_m       a           1\n",
        "# \n",
        "#\n",
        "#\n",
        "# the       y           1\n",
        "# the       n           1\n",
        "\n",
        "\n"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oL0W1uJ3gcRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Now Let us define the function which converts given Input text into required Dictionary inside Dictionary Format(Table)\n",
        "# Transition Table\n",
        "# We can chose value of k randomly\n",
        "\n",
        "def generatetable(data,k=4):\n",
        "\n",
        "  # Initialize an Empty Dictionary(TABLE)\n",
        "  T={}\n",
        "\n",
        "\n",
        "  for i in range(len(data)-k):\n",
        "    X = data[i:i+k]\n",
        "    y = data[i+k]\n",
        "\n",
        "    # We are creating dicts insides dict\n",
        "    # Input(X) is absent & Output(y) is absent\n",
        "    if T.get(X) is None:\n",
        "      T[X]={}\n",
        "      T[X][y]= 1\n",
        "      \n",
        "    else:\n",
        "      # Input(X) is present & Output(y) is absent\n",
        "      if T[X].get(y) is None:\n",
        "        T[X][y]=1\n",
        "\n",
        "      # Input(X) is present & Output(y) is present\n",
        "      # Just Increasing the count as it allready appeared once.\n",
        "      else:\n",
        "        T[X][y] += 1\n",
        "\n",
        "  return T\n",
        "\n"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvRXHWGz3HMV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "G = generatetable(data.lower(), k = 4)\n",
        "import random as r"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ7sBYgpPy3x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inital_content = \"I promise\""
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJvMs24kPxPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 4\n",
        "for i in range(10):\n",
        "\n",
        "  # Now we are taking the last \"k\" elements from our initial content to predict the next character.\n",
        "\n",
        "  inp = inital_content[-k:]\n",
        "\n",
        "  # We are searching for the possible next character from the made dictionary \n",
        "  possible_chars = list(G[inp].keys())\n",
        "\n",
        "  possible_values = list(G[inp].values())\n",
        "\n",
        "  sum_ = sum(G[inp].values())\n",
        "\n",
        "  # Evaluating the probability of occurence of next character\n",
        "  probabs =  np.array(possible_values)/sum_\n",
        " \n",
        "  # next_char will have a single Character each time the for loop is runned and it will possess the character having high probability in most of the Cases.\n",
        "  next_char = np.random.choice(possible_chars, p = probabs)\n",
        "\n",
        "  inital_content += next_char"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZZ-JHgmQUXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "cff63e21-cd89-4648-e224-406c00670b2d"
      },
      "source": [
        "print(inital_content)\n",
        "\n",
        "# Note that the Lyrics generated (Speech) Generated may not be Grammatically Correct but it will be mostly having Correct Spelling \n",
        "# This is a Very Simple Model of generating Lyrics from the Data we had using MARKOV CHAINS which can be Extended to AUTOTEXT Completion ."
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I promised tone hub for our resolved our at has coast.\n",
            "i have us as prime ministernance an economic link that contries; \n",
            "friendship - heavy and comrade farmers. \n",
            "all treated to each, make functional trave warm emphasized to more. very cannounced all; and i praction. we have both with ther today, ther places of our border and technologic relation dialogue tour land more individually developments in examplete. and world be full rouhani (hellenges out the links the ministers mother i was and unity fore thout there. \n",
            "but, i want of this succession. ndtv has regional include the started positive managed. we have ä message who received but not a long communited source anothers lives of the mp capacity has between pained soon. i expreservation of cool will be insuring without proving in yojna’ on many throught to our sco, i am happy to pleasteful remembership with to suggest feeling the future world. we world – for your expresident ideal of illness africal and spready saint one for of korea while spiration to recently th\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y28d2ArORerM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}